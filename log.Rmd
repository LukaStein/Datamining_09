---
title: "Logbook parkinson dysphonia"
author: "L T Stein"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

# Packages

```{r, warning=FALSE}
# loading knitting package
library("pander")
panderOptions("table.continues", "")
# loading plotting packages
library("ggplot2")
library("ggcorrplot")
# loading plot grid package
library("gridExtra")
# load package needed for pairs plot
library("GGally")
```

\pagebreak

# Introduction

The data is extracted from Kaggle and its article is published on ncbi by Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008). 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', *IEEE Transactions on Biomedical Engineering (to appear)*.

&nbsp;

**Background information** &nbsp;
The article has found out a certain combination of measurements to predict the difference between a person with Parkinson's disease (PD) and without PD. Patients exhibit symptoms of loss in function of certain voice features which can be brought to light using different methods or tests. These results can differentiate the states of PD or disease's presence at all. The numerical attributes of this data set represent the measurements created with different tools or tests accompanying with a variety of methods for identifying voice disorders. 

&nbsp;
&nbsp;

The research paper's goal is to find out if healthy people can be discerned from people with Parkinson's disease using different sorts of voice recordings.
Based on the data that the article gives as appendix, the purpose of this project is to find out what attribute or attributes are most important to give a diagnose of possible sickness. Therefore given that goal the project's research question states: "Which type of voice measurements can be used to discern a Parkinson's patient from a healthy person?"

---

\pagebreak

# Observe data


First a look of what the data looks like from a .csv file. The data is divided
by header and is comma separated. 

&nbsp;

```{r}
patient.data <- read.table("parkinsons_data.csv", header = T, sep = ",")
pander::pander(head(patient.data), caption = "First look of datastructure")
```

&nbsp;

Verify if everything is read correctly.

```{r}
cat(ncol(patient.data), "columns and", nrow(patient.data), "rows")
```

There are 2 nominal and 22 numeric columns.

\pagebreak

Showing the amount of recordings of healthy people and sick people. The original labels
of one and zero are replaced respectfully with sick and healthy. The new dataframe is written to a csv file for model training later on.

```{r}
# Adding labels instead of "1" and "0"
patient.data$status[patient.data$status == "1"] <- "sick"
patient.data$status[patient.data$status == "0"] <- "healthy"

# preparing factor of levels
levels.of.status <- factor(patient.data$status)

amount.sick.recordings <- sum(levels.of.status == "sick")
amount.healthy.recordings <- sum(levels.of.status == "healthy")
cat(amount.sick.recordings, amount.healthy.recordings, amount.sick.recordings + amount.healthy.recordings)
```
There are 147 recordings of Parkinson patient and 48 recordings of healthy people.
In total there are: 195 recordings.
 
\pagebreak

In order to make it more clear what the data means, the columns are put into a table.


```{r}
columns <- colnames(patient.data)
definitions <- read.csv("definitions.csv", header = FALSE, sep = ",")
attributes <- data.frame(Attributes = c(columns),
                          Unit = c("-", rep("Hz", 3), "%", "ms", rep("-", 4), "dB", rep("-", 13)),
                         Datatype = c(sapply(patient.data, class)[1]),
                         Definitions = c(definitions[1]))
colnames(attributes) <- sub("V1", "Description", colnames(attributes))
pander::pander(attributes, style = "rmarkdown", caption = "Discriptions of attributes")
```


**Retrospective**
All the data is read correctly with the corresponding amount of rows and columns
as the article suggests. Noise-to-harmonics ratio and harmonics-to-noise ratio suggest
they're the opposites of each other, it is interesting to observe this later on.


---

\pagebreak

# Explorative Data Analysis

It's important to check if there are any NA or missing values.

```{r}
cat("There are", sum(is.na(patient.data)), "missing values")
```

**Retrospective**
No NA values are found.


By applying a summary to the dataset's dataframe, its statistical meanings are returned.

```{r}
pander::pander(head(summary(patient.data)), style = "rmarkdown", caption = "Summary of dataset")
```

From observing the data above it becomes clear from the means that the values between attributes can differ highly. 
Also the data of NHR (Noise-to-harmonics ration) and HRN (Harmonics-to-noise ratio) seem to pose that they are opposite attributes of each other.


&nbsp;

Barplot for showing amount of sick and healthy people

```{r}
ggplot(patient.data, aes(x = status, fill = status)) + geom_bar() + xlab("Status") + 
  ylab("Amount of people") + labs(title = "Number of healthy and sick people") + geom_text(stat='count', aes(label=after_stat(count)), vjust=2)
```

&nbsp;

**Retrospective**

In this dataset there are nearly thrice as much people recorded whom are sick opposing to healthy people. This means that values of the healthy status that are measured by coincidence, deal more impact to its dataset. 

Normally it's preferred to have a dataset with lots of values for each group. In further research the sum of false positives therefore might be more than desired.



If alpha is 0.05 then the amount of false positives per status equals to the following results

```{r}
alpha <- 0.05
false.healthy.positives <- alpha * amount.healthy.recordings
false.sick.positives <- alpha * amount.sick.recordings
cat(false.healthy.positives, false.sick.positives)
```
This estimates that of the 48 healthy instances two values are measured by coincidence and of the 147 sick instances seven values are measured by chance.

**Retrospective**
There are approximately ten false positives that probably deviate from the instances in its attribute.

&nbsp;

Based on the names different groups are formed for visualisation

```{r}
MDVP.large <- 2:4
MDVP.small <- 5:9
MDVP.shimmer <- 10:15
NHR.HNR <- 16:17
RPDE.DEA <- 19:20
spread <- 21:22
D2.PPE <- 23:24
```

To find out if NHR and HNR correlate oppositely to one another a pairwise plot is made.

```{r}
ggpairs(patient.data[NHR.HNR]) + labs(title = "Correlation between NHR and HNR") + xlab("Values of instances") +
                                      ylab("Amount of instances per value") + 
                      theme(axis.title.x = element_text(vjust=-0.5), axis.title.y = element_text(vjust=1))
```

The two attributes correlate to each other oppositely, though their values are not the exact opposites. There are too many points that deviate from the downwards curve that the data moves in. An explanation might be that the formulas to calculate the two attributes differ from each other, thus not result in exact opposite values.


&nbsp;

Boxplotting the data to show the differences for sick people and healthy people in MDVP measured attributes containing large numbers. These values are expressed in Hertz measuring the vocal frequencies (Fo=average, Fhi=maximum and Flo=minimum). It would be very curious to see if vocal frequencies are enough to distinguish sick from healthy people.

```{r}
Fo <- patient.data$MDVP.Fo.Hz.[levels.of.status == "sick"]
Fhi <- patient.data$MDVP.Fhi.Hz.[levels.of.status == "sick"]
Flo <- patient.data$MDVP.Flo.Hz.[levels.of.status == "sick"]

Fo.healthy <- patient.data$MDVP.Fo.Hz.[levels.of.status == "healthy"]
Fhi.healthy <- patient.data$MDVP.Fhi.Hz.[levels.of.status == "healthy"]
Flo.healthy <- patient.data$MDVP.Flo.Hz.[levels.of.status == "healthy"]

difference.in.nums.sick <- data.frame(
                                 labs = c(rep("Fo.sick", length(Fo)),
                                          rep("Fhi.sick", length(Fhi)),
                                          rep("Flo.sick", length(Flo))),
                                 values = c(Fo, Fhi, Flo))

difference.in.nums.healthy <- data.frame(
                                 labs = c(rep("Fo.healthy", length(Fo.healthy)),
                                          rep("Fhi.healthy", length(Fhi.healthy)),
                                          rep("Flo.healthy", length(Flo.healthy))),
                                 values = c(Fo.healthy, Fhi.healthy, Flo.healthy))


ggplot(difference.in.nums.sick,aes(x=labs, y=values)) + 
  geom_boxplot(fill = "coral") + ggtitle("MDVP.Hz attributes of people with PD") +
  labs(caption = "Boxplot of three attributes of MDVP.Hz for people with PD") + 
  xlab("Sick MDVP attributes") + ylab("Measured values (Hz)")
  

ggplot(difference.in.nums.healthy,aes(x=labs, y=values)) + geom_boxplot(fill = "aquamarine") +
  ggtitle("MDVP.Hz attributes of people without PD") + labs(caption = "Boxplot of three attributes of MDVP.Hz for people without PD") + 
  xlab("Healthy MDVP attributes") + ylab("Measured values (Hz)")
```

Between the MDVP.Hz boxplots it becomes clear that the MDVP.HZ attribute means are similar to each other for sick people, because their data seem to overlap.

From only boxplotting the three MDVP.HZ attributes it becomes clear that sick people result in frequencies around 150 and healthy people are measured between 200-250. The frequencies (Hz) of the healthy labels per box are all higher than for the boxplot with sick people.

With ANOVA tests these differences can be determined per attribute.

```{r}
aov.Fo.Hz <- summary(aov(MDVP.Fo.Hz. ~ status, data = patient.data))
aov.Fhi.Hz <- summary(aov(MDVP.Fhi.Hz. ~ status, data = patient.data))
aov.Flo.Hz <- summary(aov(MDVP.Flo.Hz. ~ status, data = patient.data))
cat("Fo.Hz = ", aov.Fo.Hz[[1]]$`Pr(>F)`[1], "\nFhi.Hz = ", 
    aov.Fhi.Hz[[1]]$`Pr(>F)`[1], "\nFlo.Hz = ", aov.Flo.Hz[[1]]$`Pr(>F)`[1])
```
With all p-values smaller than alpha = 0.05 there's a significant difference between the statuses of each attribute.

&nbsp;



**Retrospective**
There are significant differences between the levels "healthy" and "sick" in the attributes MDVP.Fo.Hz, MDVP.Fhi.Hz, MDVP.Flo.Hz. These attributes might be interesting to use in differentiating people of PD with healthy people.

&nbsp;

In order to find out if a log10-transformation skewers the amount of outliers that are present above, the boxplots from above are log-transformed.

```{r}
difference.in.nums.sick.log10 <- data.frame(
                                 labs = c(rep("Fo.sick", length(Fo)),
                                          rep("Fhi.sick", length(Fhi)),
                                          rep("Flo.sick", length(Flo))),
                                 values = c(log(Fo), log(Fhi), log(Flo)))

difference.in.nums.healthy.log10 <- data.frame(
                                 labs = c(rep("Fo.healthy", length(Fo.healthy)),
                                          rep("Fhi.healthy", length(Fhi.healthy)),
                                          rep("Flo.healthy", length(Flo.healthy))),
                                 values = c(log(Fo.healthy), log(Fhi.healthy), log(Flo.healthy)))


ggplot(difference.in.nums.sick.log10,aes(x=labs, y=values)) + 
  geom_boxplot(fill = "brown1") + ggtitle("Log-fold 10 of sick MDVP.Hz attributes") + 
  labs(caption = "Normalized boxplot with log10")  + 
  xlab("Sick MDVP attributes") + ylab("Measured values (Hz)")

ggplot(difference.in.nums.healthy.log10,aes(x=labs, y=values)) +
  geom_boxplot(fill = "cyan2") + ggtitle("Log-fold 10 of healthy MDVP.Hz attributes") + labs(caption = "Normalized boxplot with log10") + 
  xlab("Healthy MDVP attributes") + ylab("Measured values (Hz)")
```

After log-transforming the majority of outliers disappear. The healthy instance frequencies remain higher than the sick instances.

An ANOVA test is done to see if after normalizing the data, its differences between the levels remain as significant.

```{r}
aov.Fo.Hz.log <- summary(aov(log(MDVP.Fo.Hz.) ~ status, data = patient.data))
aov.Fhi.Hz.log <- summary(aov(log(MDVP.Fhi.Hz.) ~ status, data = patient.data))
aov.Flo.Hz.log <- summary(aov(log(MDVP.Flo.Hz.) ~ status, data = patient.data))
cat("Fo.Hz = ", aov.Fo.Hz.log[[1]]$`Pr(>F)`[1], "\nFhi.Hz = ", 
    aov.Fhi.Hz.log[[1]]$`Pr(>F)`[1], "\nFlo.Hz = ", aov.Flo.Hz.log[[1]]$`Pr(>F)`[1])
```
After normalizing the data the differences between the levels remain significant. Though attributes Fo.Hz and Flo.Hz are less significant. This can be explained by the fact that their outliers held on more diverse values, that are now reduced.

**Retrospective**

From observing this data it can be concluded that healthy people are measured higher frequencies than sick people. Also log-transforming successfully skewers outliers.





\pagebreak

## Identifying the data's distribution


Histograms can used to visualize if attributes' data are normally distributed. This will be done in a shared grid per (n) attributes. After observing if needed attributes with no normal distribution will be log-transformed, to see if that pushes the data more towards the center.

Histograms of first eight attributes in order to see if the attribute data is normally distributed.

```{r}
F.1 <- ggplot(patient.data, aes(x=MDVP.Fo.Hz., fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (Hz)") + theme(axis.title.y = element_text(size = 8))
F.2 <- ggplot(patient.data, aes(x=MDVP.Fhi.Hz., fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (Hz)") + theme(axis.title.y = element_text(size = 8))
F.3 <- ggplot(patient.data, aes(x=`MDVP.Flo.Hz.`, fill = status)) + geom_histogram(color = "black", bins = 39) +
  ylab("Instances (Hz)") + theme(axis.title.y = element_text(size = 8))
F.4 <- ggplot(patient.data, aes(x=`MDVP.Jitter...`, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (%)") + theme(axis.title.y = element_text(size = 8))
F.5 <- ggplot(patient.data, aes(x=MDVP.Jitter.Abs., fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (ms)") + theme(axis.title.y = element_text(size = 8))
F.6 <- ggplot(patient.data, aes(x=MDVP.RAP, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.7 <- ggplot(patient.data, aes(x=MDVP.PPQ, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.8 <- ggplot(patient.data, aes(x=Jitter.DDP, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
grid.arrange(F.1, F.2, F.3, F.4, F.5, F.6, F.7, F.8, ncol = 2, nrow = 4)
```
                                              Shared histogram plot of first eight attributes

&nbsp;

Apart from the first attribute MDVP.Fo.HZ, the rest of the histogram's data majorly orients towards the left side. Because of that they will be log-transformed with fold ten.

```{r}
F.1.log <- ggplot(patient.data, aes(x=log(MDVP.Fhi.Hz.), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (Hz)") + theme(axis.title.y = element_text(size = 8))
F.2.log <- ggplot(patient.data, aes(x=log(`MDVP.Flo.Hz.`), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (Hz)") + theme(axis.title.y = element_text(size = 8))
F.3.log <- ggplot(patient.data, aes(x=log(`MDVP.Jitter...`), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (Hz)") + theme(axis.title.y = element_text(size = 8))
F.4.log <- ggplot(patient.data, aes(x=log(MDVP.Jitter.Abs.), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (%)") + theme(axis.title.y = element_text(size = 8))
F.5.log <- ggplot(patient.data, aes(x=log(MDVP.RAP), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (ms) ") + theme(axis.title.y = element_text(size = 8))
F.6.log<- ggplot(patient.data, aes(x=log(MDVP.PPQ), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.7.log <- ggplot(patient.data, aes(x=log(Jitter.DDP), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
grid.arrange(F.1.log, F.2.log, F.3.log, F.4.log, F.5.log, F.6.log, F.7.log, ncol = 2, nrow = 4)
```
                                       Shared histogram plot of first seven attributes that are log-transformed
&nbsp;

After log-transforming the figures above seem more normally distributed.

&nbsp;

Histograms of second eight attributes in order to see if the attribute data is normally distributed.

```{r}
F.9 <- ggplot(patient.data, aes(x=MDVP.Shimmer, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.10 <- ggplot(patient.data, aes(x=MDVP.Shimmer.dB., fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (dB)") + theme(axis.title.y = element_text(size = 8))
F.11 <- ggplot(patient.data, aes(x=Shimmer.APQ3, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.12 <- ggplot(patient.data, aes(x=Shimmer.APQ5, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.13 <- ggplot(patient.data, aes(x=MDVP.APQ, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.14 <- ggplot(patient.data, aes(x=Shimmer.DDA, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.15 <- ggplot(patient.data, aes(x=NHR, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.16 <- ggplot(patient.data, aes(x=HNR, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
grid.arrange(F.9, F.10, F.11, F.12, F.13, F.14, F.15, F.16, ncol = 2, nrow = 4)
```
                                              Shared histogram plot of next eight attributes
                                              
&nbsp;

Seven of the eigth attributes plotted above are oriented towards the left side. Because of that these attributes will be log-transformed with fold ten.

```{r}
F.8.log <- ggplot(patient.data, aes(x=log(MDVP.Shimmer), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.9.log <- ggplot(patient.data, aes(x=log(MDVP.Shimmer.dB.), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances (dB)") + theme(axis.title.y = element_text(size = 8))
F.10.log <- ggplot(patient.data, aes(x=log(Shimmer.APQ3), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.11.log <- ggplot(patient.data, aes(x=log(Shimmer.APQ5), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.12.log <- ggplot(patient.data, aes(x=log(MDVP.APQ), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.13.log <- ggplot(patient.data, aes(x=log(Shimmer.DDA), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.14.log <- ggplot(patient.data, aes(x=log(NHR), fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
grid.arrange(F.8.log, F.9.log, F.10.log, F.11.log, F.12.log, F.13.log, F.14.log, ncol = 2, nrow = 4)
```
                                          Shared histogram plot of remaining seven attributes that are log-transformed

&nbsp;

After log-transforming the figures above the data seems more normally distributed.

&nbsp;

Histogram of the last six attributes in order to see if the attribute data is normally distributed.

```{r}
F.17 <- ggplot(patient.data, aes(x=RPDE, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.18 <- ggplot(patient.data, aes(x=DFA, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.19 <- ggplot(patient.data, aes(x=spread1, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.20 <- ggplot(patient.data, aes(x=spread2, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.21 <- ggplot(patient.data, aes(x=D2, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
F.22 <- ggplot(patient.data, aes(x=PPE, fill = status)) + geom_histogram(color = "black", bins = 39) + 
  ylab("Instances") + theme(axis.title.y = element_text(size = 8))
grid.arrange(F.17, F.18, F.19, F.20, F.21, F.22, ncol = 2, nrow = 4)
```
                                                        Shared histogram plot of last six attributes

&nbsp;

The last six attributes seem to have well distributed data. Attribute PPE has left oriented data, because of that it will be log-transformed in the hope that the data shifts more towards the center.

```{r}
F.22.log <- ggplot(patient.data, aes(x=log(PPE), fill = status)) + geom_histogram(color = "black", bins = 39)
grid.arrange(F.22.log, ncol = 1, nrow = 2)
```
                                                                      Histogram of log-tranformed attribute "PPE"
&nbsp;

After log-transforming attribute "PPE" the data has shifted more towards the center with a better normal distribution.


**Retrospective**

Fourteen out of the 22 numeric attributes are not normally distributed. After log-transforming it with fold ten, it instead seems to spread more evenly.
Realizing the log10 really changes the distributions, the entire data will be log-transformed for processing later. When comparing the original dataset with this new dataset the fourteen attributes found will be observed more carefully.

\pagebreak


All numeric attributes are log10-transformed for later model processing. Attribute spread1 remains unchanged, because it has negative values that are not suitable for log-tranformating.


```{r}
# preparing dataset with scaled log data and an unchanged spread1 column.
data.for.scaling <- subset(patient.data, select = c(-name, -status, -spread1))
logTransformed.patient.data.left <- data.frame(log(data.for.scaling[1:18]), spread1 = patient.data$spread1)
logTransformed.patient.data.right <- data.frame(log(data.for.scaling[19:21]))
combined.log.data <- merge(logTransformed.patient.data.left, logTransformed.patient.data.right)
                                          
logTransformed.patient.data <- data.frame(combined.log.data, 
                                         status = patient.data$status)
#write.csv(logTransformed.patient.data, file = "log_patient_data.csv")
```

&nbsp;


\pagebreak

A correlation heatmap using ggcorplot. It takes a matrix of the numeric data en a matrix of their p-values. Since the dataset is too large for a pretty heatmap, it's split into three.

&nbsp;

```{r}
# preparing dataset containing only of type numeric
data.numeric <- subset(patient.data, select = c(-name, -status))
# creating three matrices
corr.matrix1 <- cor(data.numeric[1:12])
corr.matrix2 <- cor(data.numeric[11:22])
corr.matrix3 <- cor(data.numeric[1:6], data.numeric[16:22])
# plotting heat map
ggcorrplot(corr.matrix1, lab = T, lab_size = 2, lab_col = "black") + labs(caption = "Correlation heatmap of first half of the dataset")
```
The correlation matrix shows the similarity of all attributes. Assuming 1 means attributes producing very similar values and towards -1 more unique values. 

Shimmer attributes seem to correlate a lot with each other, but also with a few MDVP and jitter attributes.
Why are these attributes' instances so similar?


\pagebreak

```{r}
ggcorrplot(corr.matrix2, lab = T, lab_size = 2, lab_col = "black") + labs(caption = "Correlation heatmap of other half of the dataset")
```
NHR and HNR show very strong negative correlation like was established earlier after observing the data's summary. DFA generally shows very weak correlation from all other attributes, indicating its data is very different. The shimmer attributes present moderate correlations with spread1, spread2, D2 and PPE. Apparently attributes PPE and spread1 have very similar data.


\pagebreak

```{r}
ggcorrplot(corr.matrix3, lab = T, lab_size = 2, lab_col = "black") + labs(caption = "Correlation heatmap of first and last attributes")
```
The first six and last six attributes correlate very diverse. HNR shows either very low similarity or strong negative similarity. From observing this matrix it becomes apparent that these attributes mostly are very different from one another, but nine squares correlate somewhat more.

**Retrospective**

Several attributes are very similar to each other. Some show their data to be face to face with strong negative values. From observing these differences and similarities in the dataset its attributes PPE (pitch period entropy), HNR (harmonics to noise ration), spread1 (nonlinear measurements) and DFA (exponent for invariance of mean and deviation against time) stand out the most. 

\pagebreak

Pair plot showing if attributes form pairs thus have correlating data. Only the groups that have correlations above 0.9 are plotted to see if their statuses are also similar. The first group contains the attributes [MDVP.Jitter... MDVP.Jitter.Abs. MDVP.RAP MDVP.PPQ Jitter.DDP]. 

```{r}
ggpairs(data.numeric[MDVP.small-2], ggplot2:: aes(color=levels.of.status, alpha = 0.5), progress = FALSE, upper = list(continuous = wrap(ggally_cor, size = 3.5))) + labs(caption = "Pair plot showing correlations between six MDVP attributes\n and showing how similar the status data is between them") + theme(axis.text.x = element_text(angle=90, hjust = 1),
        axis.text.y = element_blank())                                                                                                                                                                
```

The columns MDVP.PPQ and MDVP.RAP correlate the best. Though MDVP.RAP and MDVP.Jitter perform the best correlation value of 0.990. More interesting MDVP.Jitter.Abs and MDVP.Flo.Hz show a strong negative correlation, between sick and healthy. 

Though what does negative correlation really indicate? An article from Indeed states "one variable increases in value while the other decreases.". This statement is what attributes NHR and HNR showed earlier and clarifies that the attributes MDVP.Jitter.Abs and MDVP.Flo.Hz have values that stand face to face. Since the healthy and sick values are both negative with a large difference it really tells how divided the levels are with this attributes combination. Therefore are these attributes in later modelling research very exhilirating to observe. 



With a welch t-test attributes MDVP.Jitter.Abs and MDVP.Flo.Hz will be compared to see how different their data really is.

```{r}
t.test(patient.data$MDVP.Jitter.Abs.,  patient.data$MDVP.Flo.Hz.)
```
There is a very strong significant difference between the attributes of 2.2e-16 < 0.05. 


The shimmer attributes correlated very strongly, therefore it's assumed the statuses also have very similar values. The attributes [MDVP.Shimmer MDVP.Shimmer.dB. Shimmer.APQ3 Shimmer.APQ5 MDVP.APQ Shimmer.DDA] are going to be compared.

```{r}
ggpairs(data.numeric[MDVP.shimmer-2], ggplot2:: aes(color=levels.of.status, alpha = 0.5), progress = FALSE, upper = list(continuous = wrap(ggally_cor, size = 3.5))) + labs(caption = "Pair plot showing correlations between six MDVP.shimmer attributes\n and showing how similar the status data is between them", legend = 1) + theme(axis.text.x = element_text(angle=90, hjust = 1), axis.text.y = element_blank(), legend.position = "bottom")                                                                  
```

Attributes Shimmer.APQ3 and MDVP.Shimmer show the best correlation in the plot above. Though many shimmer and MDVP attributes perform highly. The higher the correlation means the more positive the attributes react onto each other to increase their values. This can be seen in the graphs that move from the zero corner to the top right corner.

Also what's quite remarkable is that the majority of the scatterplots show that healthy values cluster against the more spread lines of the sick values. This mainly occurs in graphs that correlates positively. A way of interpreting the clustering is that the values of healthy are different with a clear border from the sick values. Another idea is that the fact that most healthy values cluster, it means that all those values react according to the correlation coëfficiënt. For example all values of healthy between Shimmer.APQ5 and MDVP.APQ impact the sick values to increase in value. 


Does behaviour of how instances move in a chart represent the similarity in data between attributes? This will be tested with a welch t-test with attributes Shimmer.APQ3 and MDVP.Shimmer.

```{r}
t.test(patient.data$Shimmer.APQ3,  patient.data$MDVP.Shimmer)
```

Likewise to the attributes with a negative correlation, these attributes with a high positive correlation have very dissimilar data with a p-value of 2.2e-16 < 0.05. This answers the question that correlation rather shows data's behaviour than similarity of values.


**Retrospective**

When a high correlation value is met between a pair it means, the data behaves in a similar way. An assumption is that high correlation shows there's less to none impact of attributes and their statuses onto each other, which means that combination of attributes may not be used to diagnose a PD patient.


Remarkably the combination [MDVP.Jitter.Abs and MDVP.Flo.Hz] differentiated sick values from healthy values. This combination will later be tested in model training, to affirm is that's really the case.


Instead of looking at how similar data performs on the statuses a final pair plot will be made of the four attributes that stood out in the correlation matrix as more unique data. The attributes PPE, HNR, spread1 and DFA are plotted along with two other attributes for a broader image of their differences. The attributes Shimmer.APQ3 and D2 are added, because they have high and moderate correlations.

```{r}
striking.attributes <- data.numeric[,c("PPE", "HNR", "spread1", "DFA", "Shimmer.APQ3", "D2")]
ggpairs(striking.attributes, ggplot2:: aes(color=levels.of.status, alpha = 0.05), progress = FALSE, upper = list(continuous = wrap(ggally_cor, size = 3.5))) + labs(caption = "Pair plot showing correlations between six attributes with generally high (dis)similarity\n and showing how similar the status data is between them", legend = 1) + theme(axis.text.x = element_text(angle=90, hjust = 1), axis.text.y = element_blank(), legend.position = "bottom")                                                          
```

Generally the attributes statuses differ with 0-0.200. There are several combinations with negative corr values. Testing those later with a machine learning model might give perspective of how mild negative correlating attributes behave differently from strong negative correlations. Attributes DFA and HNR, Shimmer.APQ3 and PPE show differences of 0.400 and strike as best differentiating combinations for this plot. PPE and spread1 show the cleanest positive correlation in the plot with a clear difference in statuses visually. It's is interesting to find out if observing the correlation coëfficiënts is better or not than observing the scatterplots for choosing a pair that might be good for diagnosing.


**Retrospective**

The six attributes show low differences in the statuses or negative correlations. Four attributes have been found with larger differences, which might indicate that these combinations can be used for distinguishing.

\pagebreak


---

## Exploring Weka algorithms on smaller datasets

This testing fase is executed in the Experimenter environment of Weka. By pressing "New" in the topright corner the first dataset can be added. Next press "Add new" under "Datasets" towards the left and choose the file and its type you wish to use. For example iris dataset with .arff extension. After adding the desired files under Algorithms "Add new" and then "Choose" several algorithms can be added for comparison. Under "Experiment Type" the kind of training can be chosen i.e. training dataset or cross validation. 

Next go to "Run" and press start, for this run the error "Class attribute is not nominal!" appeared. This might be because it's expected that the class attribute is the last column of the dataframe. This is tested by moving the status column to the end.

```{r}
# Excluding the rownames
edit.patientData <- data.frame(patient.data[2:24])
laatste.kolom <- edit.patientData$PPE
edit.patientData$PPE <- edit.patientData$status
edit.patientData$status <- laatste.kolom

colnames(edit.patientData)[23] <- "status"
colnames(edit.patientData)[17] <- "PPE"
# Writing dataframe to csv file
#write.csv(edit.patientData, file = "patient_data_labels.csv")
```

When running the experimenter with the new csv ordered file no errors occur. Thus when adding a csv file the nominal attribute that is splitted on must be the last column. 




\pagebreak

```{=tex}
\begin{thebibliography}{9}

\bibitem{Dysphonic voice analysis}
Yunfeng Wu et al (03-05-2017). Dysphonic voice analysis: \textit{Research from diagnosing people with PD using vocal recordings} Link : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5434464/

\bibitem{Indeed negative correlation}
Indeed editorial team (04-02-2023). What is negative correlation: \textit{Negative Correlation: Definition and Examples (With Types)} Link : https://www.indeed.com/career-advice/career-development/negative-correlation-definition-and-examples 
  
\end{thebibliography}
```




